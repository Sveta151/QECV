{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "84bb7ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "66102dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "db2534e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../final/q2_with_summaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "dbf1fa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['claim_id', 'claim', 'claim_date', 'speaker', 'reporting_source',\n",
       "       'generated_question_1', 'judgement_1', 'summary_1', 'label_1', 'url_1',\n",
       "       'context', 'generated_question_2', 'document_weight_question_2',\n",
       "       'document_rank_question_2', 'document_url_question_2',\n",
       "       'document_question_2', 'summary_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e71ae7",
   "metadata": {},
   "source": [
    "### finding maximum siffix that we are going to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f6312922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Assume merged_df is your DataFrame\n",
    "df_columns = df.columns\n",
    "\n",
    "def get_max_suffix(columns):\n",
    "    max_suffix = 0\n",
    "    for column in columns:\n",
    "        match = re.search(r'(\\d+)$', column)\n",
    "        if match:\n",
    "            suffix = int(match.group(1))\n",
    "            if suffix > max_suffix:\n",
    "                max_suffix = suffix\n",
    "    return max_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fe811a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SUFFIX = get_max_suffix(df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9b08c37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum suffix number is: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"The maximum suffix number is:\", MAX_SUFFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "19141397",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[f'label_{MAX_SUFFIX}'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b0d5790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## some changes for this df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "87f597e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.rename(columns={'summary': 'summary_2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c109827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns= {'url_2': 'document_url_question_2'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "344c5185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_date</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reporting_source</th>\n",
       "      <th>generated_question_1</th>\n",
       "      <th>judgement_1</th>\n",
       "      <th>summary_1</th>\n",
       "      <th>label_1</th>\n",
       "      <th>document_url_question_1</th>\n",
       "      <th>context</th>\n",
       "      <th>generated_question_2</th>\n",
       "      <th>document_weight_question_2</th>\n",
       "      <th>document_rank_question_2</th>\n",
       "      <th>document_url_question_2</th>\n",
       "      <th>document_question_2</th>\n",
       "      <th>summary_2</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Due to Imran Khan's criticism of Macron's comm...</td>\n",
       "      <td>31-10-2020</td>\n",
       "      <td>Consulate General Of Pakistan France</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Did French authorities cancel the visas of 183...</td>\n",
       "      <td>No, the French authorities did not cancel the ...</td>\n",
       "      <td>The text contradicts the question. There is no...</td>\n",
       "      <td>Refuted</td>\n",
       "      <td>https://tribune.com.pk/story/1119830/diplomati...</td>\n",
       "      <td>{'generated question 1': 'Did French authoriti...</td>\n",
       "      <td>Did French authorities deport 118 Pakistani ci...</td>\n",
       "      <td>weighted</td>\n",
       "      <td>1</td>\n",
       "      <td>http://library.law.fsu.edu/Digital-Collections...</td>\n",
       "      <td>~ p p e l l a n t ,  a native-born French c i ...</td>\n",
       "      <td>The provided text does not contain any informa...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Due to Imran Khan's criticism of Macron's comm...</td>\n",
       "      <td>31-10-2020</td>\n",
       "      <td>Consulate General Of Pakistan France</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Did French authorities cancel the visas of 183...</td>\n",
       "      <td>No, the French authorities did not cancel the ...</td>\n",
       "      <td>The text contradicts the question. There is no...</td>\n",
       "      <td>Refuted</td>\n",
       "      <td>https://tribune.com.pk/story/1119830/diplomati...</td>\n",
       "      <td>{'generated question 1': 'Did French authoriti...</td>\n",
       "      <td>Did French authorities deport 118 Pakistani ci...</td>\n",
       "      <td>weighted</td>\n",
       "      <td>2</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Pakistanis_in_Fr...</td>\n",
       "      <td>in Overseas DOM-TOM RÃ©union, French Guiana, Gu...</td>\n",
       "      <td>The provided text does not mention any informa...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Due to Imran Khan's criticism of Macron's comm...</td>\n",
       "      <td>31-10-2020</td>\n",
       "      <td>Consulate General Of Pakistan France</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Did French authorities cancel the visas of 183...</td>\n",
       "      <td>No, the French authorities did not cancel the ...</td>\n",
       "      <td>The text contradicts the question. There is no...</td>\n",
       "      <td>Refuted</td>\n",
       "      <td>https://tribune.com.pk/story/1119830/diplomati...</td>\n",
       "      <td>{'generated question 1': 'Did French authoriti...</td>\n",
       "      <td>Did French authorities deport 118 Pakistani ci...</td>\n",
       "      <td>weighted</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.france24.com/en/20130404-pakistan-...</td>\n",
       "      <td>Pakistan has deported three French nationals w...</td>\n",
       "      <td>The text does not provide any information rega...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Due to Imran Khan's criticism of Macron's comm...</td>\n",
       "      <td>31-10-2020</td>\n",
       "      <td>Consulate General Of Pakistan France</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Did French authorities cancel the visas of 183...</td>\n",
       "      <td>No, the French authorities did not cancel the ...</td>\n",
       "      <td>The text contradicts the question. There is no...</td>\n",
       "      <td>Refuted</td>\n",
       "      <td>https://tribune.com.pk/story/1119830/diplomati...</td>\n",
       "      <td>{'generated question 1': 'Did French authoriti...</td>\n",
       "      <td>Did French authorities deport 118 Pakistani ci...</td>\n",
       "      <td>weighted</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.indiatoday.in/world/story/pakistan...</td>\n",
       "      <td>Pakistan assembly votes to call back envoy fro...</td>\n",
       "      <td>The text does not mention anything about Frenc...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Due to Imran Khan's criticism of Macron's comm...</td>\n",
       "      <td>31-10-2020</td>\n",
       "      <td>Consulate General Of Pakistan France</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Did French authorities cancel the visas of 183...</td>\n",
       "      <td>No, the French authorities did not cancel the ...</td>\n",
       "      <td>The text contradicts the question. There is no...</td>\n",
       "      <td>Refuted</td>\n",
       "      <td>https://tribune.com.pk/story/1119830/diplomati...</td>\n",
       "      <td>{'generated question 1': 'Did French authoriti...</td>\n",
       "      <td>Did French authorities deport 118 Pakistani ci...</td>\n",
       "      <td>weighted</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.dawn.com/news/1447788</td>\n",
       "      <td>Undocumented Pakistani immigrants hide in the ...</td>\n",
       "      <td>The text contradicts the question as it does n...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   claim_id                                              claim  claim_date  \\\n",
       "0         2  Due to Imran Khan's criticism of Macron's comm...  31-10-2020   \n",
       "1         2  Due to Imran Khan's criticism of Macron's comm...  31-10-2020   \n",
       "2         2  Due to Imran Khan's criticism of Macron's comm...  31-10-2020   \n",
       "3         2  Due to Imran Khan's criticism of Macron's comm...  31-10-2020   \n",
       "4         2  Due to Imran Khan's criticism of Macron's comm...  31-10-2020   \n",
       "\n",
       "                                speaker reporting_source  \\\n",
       "0  Consulate General Of Pakistan France          Twitter   \n",
       "1  Consulate General Of Pakistan France          Twitter   \n",
       "2  Consulate General Of Pakistan France          Twitter   \n",
       "3  Consulate General Of Pakistan France          Twitter   \n",
       "4  Consulate General Of Pakistan France          Twitter   \n",
       "\n",
       "                                generated_question_1  \\\n",
       "0  Did French authorities cancel the visas of 183...   \n",
       "1  Did French authorities cancel the visas of 183...   \n",
       "2  Did French authorities cancel the visas of 183...   \n",
       "3  Did French authorities cancel the visas of 183...   \n",
       "4  Did French authorities cancel the visas of 183...   \n",
       "\n",
       "                                         judgement_1  \\\n",
       "0  No, the French authorities did not cancel the ...   \n",
       "1  No, the French authorities did not cancel the ...   \n",
       "2  No, the French authorities did not cancel the ...   \n",
       "3  No, the French authorities did not cancel the ...   \n",
       "4  No, the French authorities did not cancel the ...   \n",
       "\n",
       "                                           summary_1  label_1  \\\n",
       "0  The text contradicts the question. There is no...  Refuted   \n",
       "1  The text contradicts the question. There is no...  Refuted   \n",
       "2  The text contradicts the question. There is no...  Refuted   \n",
       "3  The text contradicts the question. There is no...  Refuted   \n",
       "4  The text contradicts the question. There is no...  Refuted   \n",
       "\n",
       "                             document_url_question_1  \\\n",
       "0  https://tribune.com.pk/story/1119830/diplomati...   \n",
       "1  https://tribune.com.pk/story/1119830/diplomati...   \n",
       "2  https://tribune.com.pk/story/1119830/diplomati...   \n",
       "3  https://tribune.com.pk/story/1119830/diplomati...   \n",
       "4  https://tribune.com.pk/story/1119830/diplomati...   \n",
       "\n",
       "                                             context  \\\n",
       "0  {'generated question 1': 'Did French authoriti...   \n",
       "1  {'generated question 1': 'Did French authoriti...   \n",
       "2  {'generated question 1': 'Did French authoriti...   \n",
       "3  {'generated question 1': 'Did French authoriti...   \n",
       "4  {'generated question 1': 'Did French authoriti...   \n",
       "\n",
       "                                generated_question_2  \\\n",
       "0  Did French authorities deport 118 Pakistani ci...   \n",
       "1  Did French authorities deport 118 Pakistani ci...   \n",
       "2  Did French authorities deport 118 Pakistani ci...   \n",
       "3  Did French authorities deport 118 Pakistani ci...   \n",
       "4  Did French authorities deport 118 Pakistani ci...   \n",
       "\n",
       "  document_weight_question_2  document_rank_question_2  \\\n",
       "0                   weighted                         1   \n",
       "1                   weighted                         2   \n",
       "2                   weighted                         3   \n",
       "3                   weighted                         4   \n",
       "4                   weighted                         5   \n",
       "\n",
       "                             document_url_question_2  \\\n",
       "0  http://library.law.fsu.edu/Digital-Collections...   \n",
       "1  https://en.wikipedia.org/wiki/Pakistanis_in_Fr...   \n",
       "2  https://www.france24.com/en/20130404-pakistan-...   \n",
       "3  https://www.indiatoday.in/world/story/pakistan...   \n",
       "4                  https://www.dawn.com/news/1447788   \n",
       "\n",
       "                                 document_question_2  \\\n",
       "0  ~ p p e l l a n t ,  a native-born French c i ...   \n",
       "1  in Overseas DOM-TOM RÃ©union, French Guiana, Gu...   \n",
       "2  Pakistan has deported three French nationals w...   \n",
       "3  Pakistan assembly votes to call back envoy fro...   \n",
       "4  Undocumented Pakistani immigrants hide in the ...   \n",
       "\n",
       "                                           summary_2 label_2  \n",
       "0  The provided text does not contain any informa...          \n",
       "1  The provided text does not mention any informa...          \n",
       "2  The text does not provide any information rega...          \n",
       "3  The text does not mention anything about Frenc...          \n",
       "4  The text contradicts the question as it does n...          "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "9b7beda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "733f0dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['claim_id'] != 'claim_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "570477fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_1\n",
       "Refuted    10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b4fa9",
   "metadata": {},
   "source": [
    "### Our prompts for further evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c1086ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_PROMPT = \"\"\" Given the provided claim, question, and summary of the text, determine the most appropriate label for the relationship between the claim and the summary, assuming the summary serves as an answer to the question. The possible labels are:\n",
    "\n",
    "1. **Refuted**: The summary clearly contradicts the claim.\n",
    "2. **Supported**: The summary clearly supports the claim.\n",
    "3. **Not Enough Evidence**: The summary does not provide sufficient evidence to either support or refute the claim. If there are no information in the text it means its Not Enough Evidence.\n",
    "\n",
    "Claim is : [[CLAIM]]\n",
    "Question is : [[QUESTION]]\n",
    "Summary is: [[SUMMARY]]\n",
    "Based on this information, what label can you give?\n",
    "Just provide final label.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "cb42ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSING_BEST_PROMPT = \"\"\"\n",
    "Based on the provided claim, question, and summaries, determine which summary provides the most relevant information related to the claim and question.\n",
    "\n",
    "Claim: [[CLAIM]]\n",
    "Question: [[QUESTION]]\n",
    "\n",
    "Summaries:\n",
    "[[SUMMARIES]]\n",
    "\n",
    "Please choose the summary that best addresses the claim and question by providing its index.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba3f33c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "63ae9881",
   "metadata": {},
   "outputs": [],
   "source": [
    "JUDGEMENT_PROMPT = \"\"\"\n",
    "Based on the provided claim, questions and summaries, answer the questions in a single answer.\n",
    "Claim: [[CLAIM]]\n",
    "Question 1: [[QUESTION_1]]\n",
    "Summary 1: [[SUMMARY_1]]\n",
    "Question 2: [[QUESTION_2]]\n",
    "Summary 2: [[SUMMARY_2]]\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "318181e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_DEMO_STOP = '''Claim = Superdrag and Collective Soul are both rock bands.\n",
    "To validate the above claim, we have asked the following questions: \n",
    "Question 1 = Is Superdrag a rock band?\n",
    "Answer 1 = Yes\n",
    "Can we know whether the claim is true or false now?\n",
    "Prediction = No, we cannot know. \n",
    "\n",
    "Claim = Superdrag and Collective Soul are both rock bands.\n",
    "To validate the above claim, we have asked the following questions: \n",
    "Question 1 = Is Superdrag a rock band?\n",
    "Answer 1 = Yes\n",
    "Question 2 = Is Collective Soul a rock band?\n",
    "Answer 2 = Yes\n",
    "Can we know whether the claim is true or false now?\n",
    "Prediction = Yes, we can know.\n",
    "\n",
    "Claim = Jimmy Garcia lost by unanimous decision to a professional boxer that challenged for the WBO lightweight title in 1995. \n",
    "To validate the above claim, we have asked the following questions:\n",
    "Question 1 = Who is the professional boxer that challenged for the WBO lightweight title in 1995? \n",
    "Answer 1 = Orzubek Nazarov\n",
    "Can we know whether the claim is true or false now?\n",
    "Prediction = No, we cannot know.\n",
    "\n",
    "Claim = Jimmy Garcia lost by unanimous decision to a professional boxer that challenged for the WBO lightweight title in 1995. \n",
    "To validate the above claim, we have asked the following questions:\n",
    "Question 1 = Who is the professional boxer that challenged for the WBO lightweight title in 1995? \n",
    "Answer 1 = Orzubek Nazarov\n",
    "Question 2 = Did Jimmy Garcia lose by unanimous decision to Orzubek Nazarov?\n",
    "Can we know whether the claim is true or false now?\n",
    "Prediction = Yes, we can know.\n",
    "\n",
    "Claim = The Swan of Catania was taught by the Italian composer Giovanni Furno.\n",
    "To validate the above claim, we have asked the following questions: \n",
    "Question 1 = What is the nationality of Giovanni Furno?\n",
    "Answer 1 = Italian\n",
    "Can we know whether the claim is true or false now?\n",
    "Prediction = No, we cannot know.\n",
    "\n",
    "Claim = Lars Onsager won the Nobel prize when he was 30 years old.\n",
    "To validate the above claim, we have asked the following questions:  \n",
    "Question 1 = When Lars Onsager won the Nobel prize?\n",
    "Answer 1 = 1968\n",
    "Can we know whether the claim is true or false now?\n",
    "Prediction = No, we cannot know.\n",
    "\n",
    "Claim = Smith worked on the series The Handmaid's Tale that is based on a novel by Margaret Atwood. \n",
    "To validate the above claim, we have asked the following questions:\n",
    "Question 1 = Which novel The Handmaid's Tale is based on?\n",
    "Answer 1 = Margaret Atwood\n",
    "Can we know whether the claim is true or false now?\n",
    "Prediction = No, we cannot know.\n",
    "\n",
    "Claim = Smith worked on the series The Handmaid's Tale that is based on a novel by Margaret Atwood. \n",
    "To validate the above claim, we have asked the following questions:\n",
    "Question 1 = Which novel The Handmaid's Tale is based on?\n",
    "Answer 1 = Margaret Atwood\n",
    "Question 2 = Did Smith work on the series The Handmaid's Tale?\n",
    "Answer 2 = Yes\n",
    "Can we know whether the claim is true or false now?\n",
    "Prediction = Yes, we can know.\n",
    "\n",
    "Claim = The first season of the series The Handmaid's Tale was released in 2017.\n",
    "To validate the above claim, we have asked the following questions:\n",
    "Question 1 = When was the first season of the series The Handmaid's Tale released?\n",
    "Answer 1 = 2017\n",
    "Can we know whether the claim is true or false now?\n",
    "Prediction = Yes, we can know.\n",
    "\n",
    "Claim = [[CLAIM]]\n",
    "To validate the above claim, we have asked the following questions:\n",
    "[[QA_CONTEXTS]]\n",
    "Can we know whether the claim is true or false now?\n",
    "Prediction = '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "886ef6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_DEMO_SUBSEQUENT = '''Task: to verify a claim, we need to ask a series of simple questions. Here the task is given a claim and previous questions generate the following question to ask. \n",
    "This question should be:\n",
    "\n",
    "- Simple with a single subject-verb-object structure.\n",
    "- Specific and directly related to the key aspect of the claim that needs validation.\n",
    "\n",
    "Claim = Superdrag and Collective Soul are both rock bands.\n",
    "To validate the above claim, we need to ask the following simple questions sequentially: \n",
    "Question 1 = Is Superdrag a rock band?\n",
    "Answer 1 = Yes\n",
    "Question 2 = Is Collective Soul a rock band?\n",
    "\n",
    "Claim = Jimmy Garcia lost by unanimous decision to a professional boxer that challenged for the WBO lightweight title in 1995. \n",
    "To validate the above claim, we need to ask the following simple questions sequentially: \n",
    "Question 1 = Who is the professional boxer that challenged for the WBO lightweight title in 1995? \n",
    "Answer 1 = Orzubek Nazarov\n",
    "Question 2 = Did Jimmy Garcia lose by unanimous decision to Orzubek Nazarov?\n",
    "\n",
    "Claim = The Swan of Catania was taught by the Italian composer Giovanni Furno.\n",
    "To validate the above claim, we need to ask the following simple questions sequentially: \n",
    "Question 1 = What is the nationality of Giovanni Furno?\n",
    "Answer 1 = Italian\n",
    "Question 2 = Who was taught by Giovanni Furno?\n",
    "\n",
    "Claim = Smith worked on the series The Handmaid's Tale that is based on a novel by Margaret Atwood.\n",
    "To validate the above claim, we need to ask the following simple questions sequentially:\n",
    "Question 1 = Which novel The Handmaid's Tale is based on?\n",
    "Answer 1 = Margaret Atwood\n",
    "Question 2 = Who worked on the series The Handmaid's Tale?\n",
    "\n",
    "Claim = The Potomac River runs along the neighborhood where Ashley Estates Kavanaugh's wedding was held.\n",
    "To validate the above claim, we need to ask the following simple questions sequentially:\n",
    "Question 1 = Where was Ashley Estates Kavanaugh's wedding held?\n",
    "Answer 1 = Christ Church in Georgetown\n",
    "Question 2 = Which river runs along the Christ Church in Georgetown?\n",
    "\n",
    "Claim = Ulrich Walter's employer is headquartered in Cologne.\n",
    "To validate the above claim, we need to ask the following simple questions sequentially:\n",
    "Question 1 = Who is Ulrich Walter's employer?\n",
    "Answer 1 = University of Cologne\n",
    "Question 2 = Where is the University of Cologne headquartered?\n",
    "\n",
    "Claim = Lars Onsager won the Nobel prize when he was 30 years old.\n",
    "To validate the above claim, we need to ask the following simple questions sequentially: \n",
    "Question 1 = When Lars Onsager won the Nobel prize?\n",
    "Answer 1 = 1968\n",
    "Question 2 = When was Lars Onsager born?\n",
    "\n",
    "Claim = [[CLAIM]]\n",
    "To validate the above claim, we need to ask the following simple questions sequentially: \n",
    "[[QA_CONTEXTS]]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a46d5b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL=\"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71266268",
   "metadata": {},
   "source": [
    "## Label generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "00a54fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating labels for each summary\n",
    "# keeping it all in one row after each summaries \n",
    "\n",
    "\n",
    "def check_label(claim, question, summary):\n",
    "    PR_template = CHECK_PROMPT\n",
    "    example_input = PR_template.replace('[[CLAIM]]', claim.strip())\n",
    "    example_input = example_input.replace('[[QUESTION]]', question.strip())\n",
    "    example_input = example_input.replace('[[SUMMARY]]', summary.strip())\n",
    "    completion = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert annotator who assists in determining the relationship between a claim and a summary in the context of a given question. Your task is to label the summary as either Refuted, Supported, or Not Enough Evidence based on how it answers the question in relation to the claim. Just provide final label.\"},\n",
    "            {\"role\": \"user\", \"content\": example_input}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    claim = row['claim']\n",
    "    question = row[f'generated_question_{MAX_SUFFIX}']\n",
    "    summary = row[f'summary_{MAX_SUFFIX}']\n",
    "    label_column = f'label_{MAX_SUFFIX}'\n",
    "    label = check_label(claim, question, summary)\n",
    "    df.at[index, label_column] = label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c1afbf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_2\n",
       "Not Enough Evidence    8\n",
       "Refuted                2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[f'label_{MAX_SUFFIX}'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "be4cccc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_date</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reporting_source</th>\n",
       "      <th>generated_question_1</th>\n",
       "      <th>judgement_1</th>\n",
       "      <th>summary_1</th>\n",
       "      <th>label_1</th>\n",
       "      <th>document_url_question_1</th>\n",
       "      <th>context</th>\n",
       "      <th>generated_question_2</th>\n",
       "      <th>document_weight_question_2</th>\n",
       "      <th>document_rank_question_2</th>\n",
       "      <th>document_url_question_2</th>\n",
       "      <th>document_question_2</th>\n",
       "      <th>summary_2</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Due to Imran Khan's criticism of Macron's comm...</td>\n",
       "      <td>31-10-2020</td>\n",
       "      <td>Consulate General Of Pakistan France</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Did French authorities cancel the visas of 183...</td>\n",
       "      <td>No, the French authorities did not cancel the ...</td>\n",
       "      <td>The text contradicts the question. There is no...</td>\n",
       "      <td>Refuted</td>\n",
       "      <td>https://tribune.com.pk/story/1119830/diplomati...</td>\n",
       "      <td>{'generated question 1': 'Did French authoriti...</td>\n",
       "      <td>Did French authorities deport 118 Pakistani ci...</td>\n",
       "      <td>weighted</td>\n",
       "      <td>1</td>\n",
       "      <td>http://library.law.fsu.edu/Digital-Collections...</td>\n",
       "      <td>~ p p e l l a n t ,  a native-born French c i ...</td>\n",
       "      <td>The provided text does not contain any informa...</td>\n",
       "      <td>Not Enough Evidence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   claim_id                                              claim  claim_date  \\\n",
       "0         2  Due to Imran Khan's criticism of Macron's comm...  31-10-2020   \n",
       "\n",
       "                                speaker reporting_source  \\\n",
       "0  Consulate General Of Pakistan France          Twitter   \n",
       "\n",
       "                                generated_question_1  \\\n",
       "0  Did French authorities cancel the visas of 183...   \n",
       "\n",
       "                                         judgement_1  \\\n",
       "0  No, the French authorities did not cancel the ...   \n",
       "\n",
       "                                           summary_1  label_1  \\\n",
       "0  The text contradicts the question. There is no...  Refuted   \n",
       "\n",
       "                             document_url_question_1  \\\n",
       "0  https://tribune.com.pk/story/1119830/diplomati...   \n",
       "\n",
       "                                             context  \\\n",
       "0  {'generated question 1': 'Did French authoriti...   \n",
       "\n",
       "                                generated_question_2  \\\n",
       "0  Did French authorities deport 118 Pakistani ci...   \n",
       "\n",
       "  document_weight_question_2  document_rank_question_2  \\\n",
       "0                   weighted                         1   \n",
       "\n",
       "                             document_url_question_2  \\\n",
       "0  http://library.law.fsu.edu/Digital-Collections...   \n",
       "\n",
       "                                 document_question_2  \\\n",
       "0  ~ p p e l l a n t ,  a native-born French c i ...   \n",
       "\n",
       "                                           summary_2              label_2  \n",
       "0  The provided text does not contain any informa...  Not Enough Evidence  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5bb340aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['claim_id', 'claim', 'claim_date', 'speaker', 'reporting_source',\n",
      "       'generated_question_1', 'document_url_question_1', 'summary_1',\n",
      "       'label_1', 'generated_question_2', 'supported_summaries',\n",
      "       'refuted_summaries', 'not_enough_evidence_summaries', 'supported_urls',\n",
      "       'refuted_urls', 'not_enough_evidence_urls'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "unique_pairs = df[['claim_id', 'claim', 'claim_date', 'speaker', 'reporting_source', 'generated_question_1', 'document_url_question_1', 'summary_1', 'label_1', 'generated_question_2']].drop_duplicates()\n",
    "\n",
    "unique_pairs['supported_summaries'] = None\n",
    "unique_pairs['refuted_summaries'] = None\n",
    "unique_pairs['not_enough_evidence_summaries'] = None\n",
    "unique_pairs['supported_urls'] = None\n",
    "unique_pairs['refuted_urls'] = None\n",
    "unique_pairs['not_enough_evidence_urls'] = None\n",
    "\n",
    "for idx, unique_pair in unique_pairs.iterrows():\n",
    "    filtered_rows = df[\n",
    "        (df['claim_id'] == unique_pair['claim_id']) &\n",
    "        (df['claim'] == unique_pair['claim']) &\n",
    "        (df['generated_question_1'] == unique_pair['generated_question_1']) &\n",
    "        (df['document_url_question_1'] == unique_pair['document_url_question_1']) &\n",
    "        (df['summary_1'] == unique_pair['summary_1']) &\n",
    "        (df['label_1'] == unique_pair['label_1']) &\n",
    "        (df['generated_question_2'] == unique_pair['generated_question_2'])\n",
    "    ]\n",
    "    # print(f'Rows for unique pair {idx}:')\n",
    "    label_supported = filtered_rows[filtered_rows[\"label_2\"] == \"Supported\"][\"summary_2\"]\n",
    "    label_refuted = filtered_rows[filtered_rows[\"label_2\"] == \"Refuted\"][\"summary_2\"]\n",
    "    label_nee = filtered_rows[filtered_rows[\"label_2\"] == \"Not Enough Evidence\"][\"summary_2\"]\n",
    "\n",
    "    supported_url = filtered_rows[filtered_rows[\"label_2\"] == \"Supported\"][\"document_url_question_2\"]\n",
    "    refuted_url = filtered_rows[filtered_rows[\"label_2\"] == \"Refuted\"][\"document_url_question_2\"]\n",
    "    nee_url = filtered_rows[filtered_rows[\"label_2\"] == \"Not Enough Evidence\"][\"document_url_question_2\"]\n",
    "\n",
    "    unique_pairs = unique_pairs.copy()  # Make a copy to avoid SettingWithCopyWarning\n",
    "    unique_pairs.at[idx, 'supported_summaries'] = list(label_supported)\n",
    "    unique_pairs.at[idx, 'refuted_summaries'] = list(label_refuted)\n",
    "    unique_pairs.at[idx, 'not_enough_evidence_summaries'] = list(label_nee)\n",
    "    unique_pairs.at[idx, 'supported_urls'] = list(label_supported)\n",
    "    unique_pairs.at[idx, 'refuted_urls'] = list(label_refuted)\n",
    "    unique_pairs.at[idx, 'not_enough_evidence_urls'] = list(label_nee)\n",
    "print(unique_pairs.columns)\n",
    "processed_df = unique_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "9b4a750d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_date</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reporting_source</th>\n",
       "      <th>generated_question_1</th>\n",
       "      <th>document_url_question_1</th>\n",
       "      <th>summary_1</th>\n",
       "      <th>label_1</th>\n",
       "      <th>generated_question_2</th>\n",
       "      <th>supported_summaries</th>\n",
       "      <th>refuted_summaries</th>\n",
       "      <th>not_enough_evidence_summaries</th>\n",
       "      <th>supported_urls</th>\n",
       "      <th>refuted_urls</th>\n",
       "      <th>not_enough_evidence_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Due to Imran Khan's criticism of Macron's comm...</td>\n",
       "      <td>31-10-2020</td>\n",
       "      <td>Consulate General Of Pakistan France</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Did French authorities cancel the visas of 183...</td>\n",
       "      <td>https://tribune.com.pk/story/1119830/diplomati...</td>\n",
       "      <td>The text contradicts the question. There is no...</td>\n",
       "      <td>Refuted</td>\n",
       "      <td>Did French authorities deport 118 Pakistani ci...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[The summarized information contradicts the qu...</td>\n",
       "      <td>[The provided text does not contain any inform...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[The summarized information contradicts the qu...</td>\n",
       "      <td>[The provided text does not contain any inform...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   claim_id                                              claim  claim_date  \\\n",
       "0         2  Due to Imran Khan's criticism of Macron's comm...  31-10-2020   \n",
       "\n",
       "                                speaker reporting_source  \\\n",
       "0  Consulate General Of Pakistan France          Twitter   \n",
       "\n",
       "                                generated_question_1  \\\n",
       "0  Did French authorities cancel the visas of 183...   \n",
       "\n",
       "                             document_url_question_1  \\\n",
       "0  https://tribune.com.pk/story/1119830/diplomati...   \n",
       "\n",
       "                                           summary_1  label_1  \\\n",
       "0  The text contradicts the question. There is no...  Refuted   \n",
       "\n",
       "                                generated_question_2 supported_summaries  \\\n",
       "0  Did French authorities deport 118 Pakistani ci...                  []   \n",
       "\n",
       "                                   refuted_summaries  \\\n",
       "0  [The summarized information contradicts the qu...   \n",
       "\n",
       "                       not_enough_evidence_summaries supported_urls  \\\n",
       "0  [The provided text does not contain any inform...             []   \n",
       "\n",
       "                                        refuted_urls  \\\n",
       "0  [The summarized information contradicts the qu...   \n",
       "\n",
       "                            not_enough_evidence_urls  \n",
       "0  [The provided text does not contain any inform...  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "1f77ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding best summary and saving question and answer pair\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# Imitate GPT call to always return the first index\n",
    "def choose_best_summary(claim, question, summaries):\n",
    "    if not summaries:\n",
    "        return None, None\n",
    "\n",
    "    summaries_text = \"\\n\".join([f\"[[{i}]] - {summary}\" for i, summary in enumerate(summaries)])\n",
    "    prompt = CHOOSING_BEST_PROMPT.replace(\"[[CLAIM]]\", claim).replace(\"[[QUESTION]]\", question).replace(\"[[SUMMARIES]]\", summaries_text)\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert annotator who assists in determining best and most informative summary based on the provided claim, question and text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    content = completion.choices[0].message.content.strip()\n",
    "    \n",
    "    # Extract the index using regex\n",
    "    match = re.search(r'\\[\\[(\\d+)\\]\\]', content)\n",
    "    if not match:\n",
    "        match = re.search(r'(\\d+)', content)\n",
    "    \n",
    "    if match:\n",
    "        best_summary_index = int(match.group(1))\n",
    "        if best_summary_index < len(summaries):\n",
    "            return summaries[best_summary_index], best_summary_index\n",
    "        else:\n",
    "#             raise ValueError(f\"Extracted index {best_summary_index} is out of range for summaries: {content}\")\n",
    "            return summaries[0],0\n",
    "    else:\n",
    "#         raise ValueError(f\"Invalid index format in GPT response: {content}\")\n",
    "        return summaries[0],0\n",
    "\n",
    "\n",
    "# Function to apply the filtering logic and choose the best summary\n",
    "def process_row(row):\n",
    "    supported_summaries = row['supported_summaries'] if isinstance(row['supported_summaries'], list) else eval(row['supported_summaries'])\n",
    "    supported_urls = row['supported_urls'] if isinstance(row['supported_urls'], list) else eval(row['supported_urls'])\n",
    "    refuted_summaries = row['refuted_summaries'] if isinstance(row['refuted_summaries'], list) else eval(row['refuted_summaries'])\n",
    "    refuted_urls = row['refuted_urls'] if isinstance(row['refuted_urls'], list) else eval(row['refuted_urls'])\n",
    "    not_enough_evidence_summaries = row['not_enough_evidence_summaries'] if isinstance(row['not_enough_evidence_summaries'], list) else eval(row['not_enough_evidence_summaries'])\n",
    "    not_enough_evidence_urls = row['not_enough_evidence_urls'] if isinstance(row['not_enough_evidence_urls'], list) else eval(row['not_enough_evidence_urls'])\n",
    "    \n",
    "    claim_id = row['claim_id']\n",
    "    claim = row['claim']\n",
    "    question = row['generated_question_2']\n",
    "    claim_date = row['claim_date']\n",
    "    speaker = row['speaker']\n",
    "    reporting_source = row['reporting_source']\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    if supported_summaries:\n",
    "        if len(supported_summaries) == 1:\n",
    "            best_supported_summary = supported_summaries[0]\n",
    "            best_supported_url = supported_urls[0]\n",
    "        else:\n",
    "            best_supported_summary, best_supported_index = choose_best_summary(claim, question, supported_summaries)\n",
    "            best_supported_url = supported_urls[best_supported_index]\n",
    "        results.append({\n",
    "            'claim_id': claim_id,\n",
    "            'claim': claim,\n",
    "            'claim_date': claim_date,\n",
    "            'speaker': speaker,\n",
    "            'reporting_source': reporting_source,\n",
    "            'generated_question_1': row[\"generated_question_1\"], \n",
    "            'document_url_question_1': row[\"document_url_question_1\"], \n",
    "            'summary_1': row[\"summary_1\"], \n",
    "            'label_1': row[\"label_1\"],\n",
    "            'generated_question_2': question,\n",
    "            'document_url_question_2': best_supported_url, \n",
    "            'summary_2': best_supported_summary,\n",
    "            'label_2': 'Supported'\n",
    "        })\n",
    "        \n",
    "    if refuted_summaries:\n",
    "        if len(refuted_summaries) == 1:\n",
    "            best_refuted_summary = refuted_summaries[0]\n",
    "            best_refuted_url = refuted_urls[0]\n",
    "        else:\n",
    "            best_refuted_summary, best_refuted_index = choose_best_summary(claim, question, refuted_summaries)\n",
    "            best_refuted_url = refuted_urls[best_refuted_index]\n",
    "        results.append({\n",
    "            'claim_id': claim_id,\n",
    "            'claim': claim,\n",
    "            'claim_date': claim_date,\n",
    "            'speaker': speaker,\n",
    "            'reporting_source': reporting_source,\n",
    "            'generated_question_1': row[\"generated_question_1\"], \n",
    "            'document_url_question_1': row[\"document_url_question_1\"], \n",
    "            'summary_1': row[\"summary_1\"], \n",
    "            'label_1': row[\"label_1\"],\n",
    "            'generated_question_2': question,\n",
    "            'document_url_question_2': best_refuted_url, \n",
    "            'summary_2': best_refuted_summary,\n",
    "            'label_2': 'Refuted'\n",
    "        })\n",
    "        \n",
    "    if not results and not_enough_evidence_summaries:\n",
    "        if len(not_enough_evidence_summaries) == 1:\n",
    "            best_not_enough_evidence_summary = not_enough_evidence_summaries[0]\n",
    "            best_not_enough_evidence_url = not_enough_evidence_urls[0]\n",
    "        else:\n",
    "            best_not_enough_evidence_summary, best_not_enough_evidence_index = choose_best_summary(claim, question, not_enough_evidence_summaries)\n",
    "            best_not_enough_evidence_url = not_enough_evidence_urls[best_not_enough_evidence_index]\n",
    "        results.append({\n",
    "\n",
    "            'claim_id': claim_id,\n",
    "            'claim': claim,\n",
    "            'claim_date': claim_date,\n",
    "            'speaker': speaker,\n",
    "            'reporting_source': reporting_source,\n",
    "            'generated_question_1': row[\"generated_question_1\"], \n",
    "            'document_url_question_1': row[\"document_url_question_1\"], \n",
    "            'summary_1': row[\"summary_1\"], \n",
    "            'label_1': row[\"label_1\"],\n",
    "            'generated_question_2': question,\n",
    "            'document_url_question_2': best_not_enough_evidence_url, \n",
    "            'summary_2': best_not_enough_evidence_summary,\n",
    "            'label_2': 'Not Enough Evidence'\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "final_df = pd.DataFrame(columns=['claim_id', 'claim', 'generated_question_1', 'document_url_question_1', 'summary_1', 'label_1', 'generated_question_2', 'summary_2', 'label_2'])\n",
    "\n",
    "# Apply the processing function to each row\n",
    "for index, row in processed_df.iterrows():\n",
    "    processed_row_df = process_row(row)\n",
    "    final_df = pd.concat([final_df, processed_row_df], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "8df5e997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>claim</th>\n",
       "      <th>generated_question_1</th>\n",
       "      <th>document_url_question_1</th>\n",
       "      <th>summary_1</th>\n",
       "      <th>label_1</th>\n",
       "      <th>generated_question_2</th>\n",
       "      <th>summary_2</th>\n",
       "      <th>label_2</th>\n",
       "      <th>claim_date</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reporting_source</th>\n",
       "      <th>document_url_question_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Due to Imran Khan's criticism of Macron's comm...</td>\n",
       "      <td>Did French authorities cancel the visas of 183...</td>\n",
       "      <td>https://tribune.com.pk/story/1119830/diplomati...</td>\n",
       "      <td>The text contradicts the question. There is no...</td>\n",
       "      <td>Refuted</td>\n",
       "      <td>Did French authorities deport 118 Pakistani ci...</td>\n",
       "      <td>The summarized information contradicts the que...</td>\n",
       "      <td>Refuted</td>\n",
       "      <td>31-10-2020</td>\n",
       "      <td>Consulate General Of Pakistan France</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>The summarized information contradicts the que...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  claim_id                                              claim  \\\n",
       "0        2  Due to Imran Khan's criticism of Macron's comm...   \n",
       "\n",
       "                                generated_question_1  \\\n",
       "0  Did French authorities cancel the visas of 183...   \n",
       "\n",
       "                             document_url_question_1  \\\n",
       "0  https://tribune.com.pk/story/1119830/diplomati...   \n",
       "\n",
       "                                           summary_1  label_1  \\\n",
       "0  The text contradicts the question. There is no...  Refuted   \n",
       "\n",
       "                                generated_question_2  \\\n",
       "0  Did French authorities deport 118 Pakistani ci...   \n",
       "\n",
       "                                           summary_2  label_2  claim_date  \\\n",
       "0  The summarized information contradicts the que...  Refuted  31-10-2020   \n",
       "\n",
       "                                speaker reporting_source  \\\n",
       "0  Consulate General Of Pakistan France          Twitter   \n",
       "\n",
       "                             document_url_question_2  \n",
       "0  The summarized information contradicts the que...  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "721a38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#getting judgement to the summary and question based on the summary\n",
    "\n",
    "def get_judgement(claim, question_1, summary_1, question_2, summary_2):\n",
    "    judgement_input = JUDGEMENT_PROMPT.replace('[[CLAIM]]', claim.strip())\n",
    "    judgement_input = judgement_input.replace('[[QUESTION_1]]', question_1.strip())\n",
    "    judgement_input = judgement_input.replace('[[SUMMARY_2]]', summary_1.strip())\n",
    "    judgement_input = judgement_input.replace('[[QUESTION_1]]', question_2.strip())\n",
    "    judgement_input = judgement_input.replace('[[SUMMARY_2]]', summary_2.strip())\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "      model=MODEL,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert annotator who assist in providing answer based on the provided information of claim, two questions and corresponding extracted summaries of the information.\"},\n",
    "        {\"role\": \"user\", \"content\":judgement_input}\n",
    "      ]\n",
    "    )\n",
    "    \n",
    "    answer = completion.choices[0].message.content\n",
    "    return answer\n",
    "\n",
    "# Add a new column for judgements\n",
    "final_df['judgement'] = final_df.apply(lambda row: get_judgement(row['claim'], row['generated_question_1'], row['summary_1'], row['generated_question_2'], row['summary_2']), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "31e7d418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>generated_question_1</th>\n",
       "      <th>summary_1</th>\n",
       "      <th>generated_question_2</th>\n",
       "      <th>summary_2</th>\n",
       "      <th>judgement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Due to Imran Khan's criticism of Macron's comm...</td>\n",
       "      <td>Did French authorities cancel the visas of 183...</td>\n",
       "      <td>The text contradicts the question. There is no...</td>\n",
       "      <td>Did French authorities deport 118 Pakistani ci...</td>\n",
       "      <td>The summarized information contradicts the que...</td>\n",
       "      <td>No, there is no mention of French authorities ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim  \\\n",
       "0  Due to Imran Khan's criticism of Macron's comm...   \n",
       "\n",
       "                                generated_question_1  \\\n",
       "0  Did French authorities cancel the visas of 183...   \n",
       "\n",
       "                                           summary_1  \\\n",
       "0  The text contradicts the question. There is no...   \n",
       "\n",
       "                                generated_question_2  \\\n",
       "0  Did French authorities deport 118 Pakistani ci...   \n",
       "\n",
       "                                           summary_2  \\\n",
       "0  The summarized information contradicts the que...   \n",
       "\n",
       "                                           judgement  \n",
       "0  No, there is no mention of French authorities ...  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[[\"claim\", \"generated_question_1\", \"summary_1\", \"generated_question_2\", \"summary_2\", \"judgement\"]].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "539b4c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verification_status(claim, question_1, answer_1, question_2, answer_2, judgement):\n",
    "    qa_contexts_txt = f'Question 1 = {question_1}\\nAnswer 1 = {answer_1}\\n'\n",
    "    qa_contexts_txt = qa_contexts_txt + f'Question 2 = {question_2}\\nAnswer 2 = {answer_2}\\n'\n",
    "    qa_contexts_txt = qa_contexts_txt + f'Summarised Judgement = {judgement}\\n'\n",
    "    example = CODE_DEMO_STOP.replace('[[CLAIM]]', claim.strip())\n",
    "    example = example.replace('[[QA_CONTEXTS]]', qa_contexts_txt.strip())\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "      model=MODEL,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert annotator who assist in telling are we having enough information to verify claim or not based on the provided claim, questions and answers. Answer only yes or no\"},\n",
    "        {\"role\": \"user\", \"content\":example}\n",
    "      ]\n",
    "    )\n",
    "    can_we_continue = completion.choices[0].message.content\n",
    "    return can_we_continue\n",
    "\n",
    "# Add a new column for verification status\n",
    "final_df['verification_status'] = final_df.apply(lambda row: get_verification_status(row['claim'], row['generated_question_1'], row['summary_1'], row['generated_question_2'], row['summary_2'], row['judgement']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "acea9aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>claim</th>\n",
       "      <th>generated_question_1</th>\n",
       "      <th>document_url_question_1</th>\n",
       "      <th>summary_1</th>\n",
       "      <th>label_1</th>\n",
       "      <th>generated_question_2</th>\n",
       "      <th>summary_2</th>\n",
       "      <th>label_2</th>\n",
       "      <th>claim_date</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reporting_source</th>\n",
       "      <th>document_url_question_2</th>\n",
       "      <th>judgement</th>\n",
       "      <th>verification_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Due to Imran Khan's criticism of Macron's comm...</td>\n",
       "      <td>Did French authorities cancel the visas of 183...</td>\n",
       "      <td>https://tribune.com.pk/story/1119830/diplomati...</td>\n",
       "      <td>The text contradicts the question. There is no...</td>\n",
       "      <td>Refuted</td>\n",
       "      <td>Did French authorities deport 118 Pakistani ci...</td>\n",
       "      <td>The summarized information contradicts the que...</td>\n",
       "      <td>Refuted</td>\n",
       "      <td>31-10-2020</td>\n",
       "      <td>Consulate General Of Pakistan France</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>The summarized information contradicts the que...</td>\n",
       "      <td>No, there is no mention of French authorities ...</td>\n",
       "      <td>Yes, we can know.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  claim_id                                              claim  \\\n",
       "0        2  Due to Imran Khan's criticism of Macron's comm...   \n",
       "\n",
       "                                generated_question_1  \\\n",
       "0  Did French authorities cancel the visas of 183...   \n",
       "\n",
       "                             document_url_question_1  \\\n",
       "0  https://tribune.com.pk/story/1119830/diplomati...   \n",
       "\n",
       "                                           summary_1  label_1  \\\n",
       "0  The text contradicts the question. There is no...  Refuted   \n",
       "\n",
       "                                generated_question_2  \\\n",
       "0  Did French authorities deport 118 Pakistani ci...   \n",
       "\n",
       "                                           summary_2  label_2  claim_date  \\\n",
       "0  The summarized information contradicts the que...  Refuted  31-10-2020   \n",
       "\n",
       "                                speaker reporting_source  \\\n",
       "0  Consulate General Of Pakistan France          Twitter   \n",
       "\n",
       "                             document_url_question_2  \\\n",
       "0  The summarized information contradicts the que...   \n",
       "\n",
       "                                           judgement verification_status  \n",
       "0  No, there is no mention of French authorities ...   Yes, we can know.  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "11751e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now generating new question\n",
    "def generate_followup_question(claim, row):\n",
    "    qa_contexts_txt = f\"Question 1 = {row['generated_question_1']}\\nAnswer 1 = {row['summary_1']}\\n\"\n",
    "    qa_contexts_txt = qa_contexts_txt + f\"Question 2 = {row['generated_question_2']}\\nAnswer 2 = {row['summary_2']}\\n\"\n",
    "    qa_contexts_txt = qa_contexts_txt + f\"Summarised Judgement = {row['judgement']}\\n\"\n",
    "    example_followup = CODE_DEMO_SUBSEQUENT.replace('[[CLAIM]]', claim.strip())\n",
    "    example_followup = example_followup.replace('[[QA_CONTEXTS]]', qa_contexts_txt.strip())\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "      model=MODEL,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert annotator who assist in generating new question that would be required to validate claim, based on the claim, previous questions and answers. Return only question.\"},\n",
    "        {\"role\": \"user\", \"content\":example_followup}\n",
    "      ] \n",
    "    )\n",
    "    followup_question = completion.choices[0].message.content\n",
    "    return followup_question\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "\n",
    "new_rows = []\n",
    "\n",
    "for index, row in final_df.iterrows():\n",
    "    if not re.search(r'\\byes\\b', row['verification_status'], re.IGNORECASE):\n",
    "        claim = row['claim']\n",
    "        new_question = generate_followup_question(claim, row)\n",
    "        \n",
    "        new_row = row\n",
    "        new_row['generated_question_3'] = new_question\n",
    "        \n",
    "        new_rows.append(new_row)\n",
    "\n",
    "# Convert the list of new rows to a DataFrame\n",
    "new_df = pd.DataFrame(new_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "66d11f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>claim</th>\n",
       "      <th>generated_question_1</th>\n",
       "      <th>document_url_question_1</th>\n",
       "      <th>summary_1</th>\n",
       "      <th>label_1</th>\n",
       "      <th>generated_question_2</th>\n",
       "      <th>summary_2</th>\n",
       "      <th>label_2</th>\n",
       "      <th>claim_date</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reporting_source</th>\n",
       "      <th>document_url_question_2</th>\n",
       "      <th>judgement</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>generated_question_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Due to Imran Khan's criticism of Macron's comm...</td>\n",
       "      <td>Did French authorities cancel the visas of 183...</td>\n",
       "      <td>https://tribune.com.pk/story/1119830/diplomati...</td>\n",
       "      <td>The text contradicts the question. There is no...</td>\n",
       "      <td>Refuted</td>\n",
       "      <td>Did French authorities deport 118 Pakistani ci...</td>\n",
       "      <td>The summarized information contradicts the que...</td>\n",
       "      <td>Refuted</td>\n",
       "      <td>31-10-2020</td>\n",
       "      <td>Consulate General Of Pakistan France</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>The summarized information contradicts the que...</td>\n",
       "      <td>No, there is no mention of French authorities ...</td>\n",
       "      <td>Yes, we can know.</td>\n",
       "      <td>Did Imran Khan criticize Macron's comments on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   claim_id                                              claim  \\\n",
       "0         2  Due to Imran Khan's criticism of Macron's comm...   \n",
       "\n",
       "                                generated_question_1  \\\n",
       "0  Did French authorities cancel the visas of 183...   \n",
       "\n",
       "                             document_url_question_1  \\\n",
       "0  https://tribune.com.pk/story/1119830/diplomati...   \n",
       "\n",
       "                                           summary_1  label_1  \\\n",
       "0  The text contradicts the question. There is no...  Refuted   \n",
       "\n",
       "                                generated_question_2  \\\n",
       "0  Did French authorities deport 118 Pakistani ci...   \n",
       "\n",
       "                                           summary_2  label_2  claim_date  \\\n",
       "0  The summarized information contradicts the que...  Refuted  31-10-2020   \n",
       "\n",
       "                                speaker reporting_source  \\\n",
       "0  Consulate General Of Pakistan France          Twitter   \n",
       "\n",
       "                             document_url_question_2  \\\n",
       "0  The summarized information contradicts the que...   \n",
       "\n",
       "                                           judgement verification_status  \\\n",
       "0  No, there is no mention of French authorities ...   Yes, we can know.   \n",
       "\n",
       "                                generated_question_3  \n",
       "0  Did Imran Khan criticize Macron's comments on ...  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "c314583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('../final/q3_samples_dev.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45059fc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m remaining_rows \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfinal_df\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbyes\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverification_status\u001b[39m\u001b[38;5;124m'\u001b[39m], re\u001b[38;5;241m.\u001b[39mIGNORECASE):\n\u001b[1;32m      5\u001b[0m         remaining_row \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclaim_id\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclaim_id\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclaim\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclaim\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjudgement\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjudgement\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip(),\n\u001b[1;32m     20\u001b[0m         }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "remaining_rows = []\n",
    "\n",
    "for index, row in final_df.iterrows():\n",
    "    if re.search(r'\\byes\\b', row['verification_status'], re.IGNORECASE):\n",
    "        remaining_row = {\n",
    "            'claim_id': row['claim_id'],\n",
    "            'claim': row['claim'],\n",
    "            'claim_date': row['claim_date'],\n",
    "            'speaker': row['speaker'],\n",
    "            'reporting_source': row['reporting_source'],\n",
    "            'generated_question_1': row['generated_question_1'],\n",
    "            'summary_1': row['summary_1'],\n",
    "            'label_1': row['label_1'],\n",
    "            'document_url_question_1': row['document_url_question_1'],\n",
    "            'generated_question_2': row['generated_question_2'],\n",
    "            'summary_2': row['summary_2'],\n",
    "            'label_2': row['label_2'],\n",
    "            'document_url_question_2': row['document_url_question_2'],\n",
    "            'judgement': row['judgement'].replace(\"\\n\", \" \").strip(),\n",
    "        }\n",
    "        \n",
    "        remaining_rows.append(remaining_row)\n",
    "remaining_df = pd.DataFrame(remaining_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf3fedc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remaining_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mremaining_df\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../final/out_csvs/q2_enough_generated.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'remaining_df' is not defined"
     ]
    }
   ],
   "source": [
    "remaining_df.to_csv('../final/out_csvs/q2_enough_generated.csv', index  = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "90298b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_df.drop('label_2', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "b38cec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in processed_df.iterrows():\n",
    "#     row['label_1'] = row['label_1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "4d85338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "86a0ea5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
